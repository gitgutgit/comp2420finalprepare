셔술형 대비  cia tiad
트라이어도 요약 Confidentiality, Integrity and Avalability
It is only accessed to those people with the correct security clearance and integrity means data cannot be modfied by other user. Lastly the information is available to the correct person.

아래는 조금 길게 서술.
Confidentiality – preserving authorizedrestrictions on information access and disclosure, including means forprotecting personal privacy andproprietary information.
Integrity — guarding against improperinformation modification or destructionand ensuring information non-repudiationand authenticity.
Availability – ensuring timely and reliable access to and use of information

Authenticity refers to the assurance that information is genuine, accurate, and trustworthy. It involves verifying the identity of the sender and ensuring that the information has not been tampered with or modified in an unauthorized manner. Authenticity measures are put in place to prevent forgery, unauthorized alterations, or misrepresentation of information. By ensuring authenticity, organizations can maintain trust in the information they receive and rely on its accuracy and reliability.

기밀성 – 개인 정보 보호 및 소유권 정보 보호 수단을 포함하여 정보 액세스 및 공개에 대한 권한 있는 제한 사항을 유지합니다.
무결성 - 부적절한 정보 수정 또는 파괴를 방지하고 정보 거부 및 신뢰성을 보장합니다.
가용성 – 정보에 대한 적시의 안정적인 액세스 및 사용 보장


Authenticity 은 정보가 진실되고 정확하며 신뢰할 수 있는 것임을 보장하는 것을 말합니다. 이는 발신자의 신원을 확인하고 정보가 무단으로 변경되거나 수정되지 않았음을 보장하는 것을 포함합니다. 정통성 조치는 위조, 무단 변경 또는 정보의 잘못된 표현을 방지하기 위해 시행됩니다. 정보의 정통성을 보장함으로써 조직은 받은 정보에 대해 신뢰를 유지하고 그 정확성과 신뢰성에 의존할 수 있습니다.

==암호 hash? 판단 규칙3개

1.hash1 violates the deterministic property. 랜덤 가챠등.. 복호화가 불가능한 결정불가능성질일떄

2.1The output length is variable
2.2And hash2 violates pre-image resistantance (we can figure out the character mappings) 예측가능한 mapping느낌이어서..

3.hash3 violates collosion resistantance. We can easily come up with message pairs that hash to the same value.
 다른문자가 같은값이 나올수있음 충돌

RSA

#쉽게요약하면 남한테 받은 랜덤 넘버^자기 넘버 제곱    mod 공용 primenumber      = 어떤값 이게 common secret key
# 보내는값 은    generator ^자기랜덤 mod prime number
아래는 예시
p=31; g=13; a=12; b=7;
A = pow(g,a,p) #이게 유용함 g^a mod p임
B = pow(g,b,p)
K = pow(B,a,p)
K2 = pow(A,b,p)
print(A)
print(B)
print(K)
print(K2)

프라이베잇 PUBLICK KEY 기호 와 공식들
p=3; q=11; e=7; d=3; m=34;
n=p*q;
#  N = p*q   is formula 
 #   r = (p-1)*(q-1) 
print(f'Alice\'s private key is ({d},{n})') #  d ,n    m = c^d mod N
print(f'Alice\'s public key is ({e},{n})') # e,n 약속같은느낌  c = m^e mod N => crypto message 공식  문자^e mod n










Ethics
Describe a PET and how they can be used to mitigate a number of ethical risks that have been brought up over the course of the semester.

PET(Privacy enhancing Technologies) has been mainly be used by online users to protect the privacy of their personal data. An example is Pseudonymization, where the identifiers are replaced by pseudonyms, so the data would be less identifiable when running data analysis. This could have helped the Apple's credit card issue we talked about in Lab7, general collective of data eg via chatbot.  




Discuss why it is important to consider ethical implications when creating a machine learning model to predict the amount of credit someone can receive on a credit card.
요약하자면 윤리적인걸 안따지면 차별점이 생길수가있다 APPLECARD사태처럼 여성차별등
Take for example the Apple's credit card discussed before. If we do not consider ethical implications, and not check the data, the model could have been using implied data to identify certain people and find unintended pattern in predicting the credit one should receive. 







비대칭과 대칭 암호학

Asymmetric cryptography, also known as public-key cryptography, is a cryptographic system that uses a pair of mathematically related keys for encryption and decryption: a public key and a private key. The public key is openly distributed and can be used by anyone to encrypt messages or verify digital signatures. The private key, on the other hand, is kept secret and is used for decrypting messages or generating digital signatures. The key pair is asymmetric because the public key cannot be used to derive the private key, ensuring the security of the system.

Symmetric cryptography, also known as secret-key cryptography, is a cryptographic system that uses the same key for both encryption and decryption. In this system, the same secret key is used by both the sender and the receiver to encrypt and decrypt messages. Since the same key is used, symmetric cryptography is typically faster and more efficient than asymmetric cryptography, but it requires secure distribution of the secret key to maintain confidentiality.

Here's an example to illustrate the difference between asymmetric and symmetric cryptography




비대칭 암호화(Asymmetric cryptography)는 공개키 암호화라고도 불리며, 암호화와 복호화를 위해 수학적으로 연관된 두 개의 키, 즉 공개키와 개인키를 사용하는 암호화 시스템입니다. 공개키는 공개적으로 배포되며 누구나 메시지를 암호화하거나 디지털 서명을 확인하는 데 사용할 수 있습니다. 반면, 개인키는 비밀로 유지되며 메시지를 복호화하거나 디지털 서명을 생성하는 데 사용됩니다. 이러한 키 쌍은 비대칭적인 특성을 가지며, 공개키로부터 개인키를 유도할 수 없어 시스템의 보안을 보장합니다.

대칭 암호화(Symmetric cryptography)는 대칭키 암호화라고도 불리며, 암호화와 복호화에 동일한 키를 사용하는 암호화 시스템입니다. 이 시스템에서는 발신자와 수신자 모두 동일한 비밀 키를 사용하여 메시지를 암호화하고 복호화합니다. 동일한 키를 사용하기 때문에 대칭 암호화는 일반적으로 비대칭 암호화보다 더 빠르고 효율적이지만, 기밀성을 유지하기 위해 비밀 키의 안전한 배포가 필요합니다.

다음은 비대칭 암호화와 대칭 암호화의 차이를 설명하는 예시입니다:

앨리스가 밥에게 비밀 메시지를 보내고자 할 때:

비대칭 암호화:

밥은 공개키와 개인키의 키 쌍을 생성합니다.
밥은 자신의 공개키를 앨리스와 공유합니다.
앨리스는 밥의 공개키를 사용하여 메시지를 암호화합니다.
앨리스는 암호화된 메시지를 밥에게 보냅니다.
밥은 개인키를 사용하여 메시지를 복호화합니다.
대칭 암호화:

앨리스와 밥은 미리 공유한 비밀 키를 합의합니다.
앨리스는 비밀 키를 사용하여 메시지를 암호화합니다.
앨리스는 암호화된 메시지를 밥에게 보냅니다.
밥은 동일한 비밀 키를 사용하여 메시지를 복호화합니다.
비대칭 암호화의 예시에서는 밥의 공개키가 암호화에 사용되고, 개인키가 복호화에 사용됩니다. 대칭 암호화의 예시에서는 앨리스와 밥이 모두 동일한 비밀 키를 암호화와 복호화에 사용합니다.


















ETHICS 2022 답변

Q2.1: Ethics of using AI in the medical field

Without a specific case study provided, I'll address the general social and ethical implications of AI in medicine. AI applications in healthcare have potential for vast benefits, like increasing efficiency and improving diagnosis. However, there are ethical issues to consider. Firstly, patient privacy is a concern as AI requires extensive data. Ensuring secure and ethical data handling is paramount. Secondly, AI systems could be biased if training data lacks diversity, leading to unequal healthcare outcomes. Lastly, the use of AI could decrease human interaction in healthcare, which might affect patients' experiences.

Q2.2: Explainable AI

AI models that predict outcomes not understandable by human experts raise ethical concerns. Transparency and understandability are key principles in ethical AI use. Without understanding how AI reaches a decision, we can't ensure fairness, accountability, or correct any errors. Relying on 'black box' models might result in wrong predictions, possibly endangering lives in healthcare. Until these AI systems are explainable and their decisions interpretable, their use in critical sectors like healthcare should be limited or coupled with human oversight.

Q2.3: Decision-Making

When interpreting results from AI models in healthcare, considerations include: reliability, understanding whether the model's accuracy has been validated with diverse, independent data; explainability, whether the model’s decisions are interpretable; fairness, ensuring the model isn't biased against certain groups; and the consequences of a wrong decision, particularly when lives are at stake. Additionally, there should be human oversight to validate AI decisions and ensure patients' rights are protected. The AI model should complement human judgement, not replace it.

한글 답변
Q2.1: 의료 분야에서 AI 사용의 윤리

특정한 사례 연구가 제공되지 않았으므로, 의료 분야에서의 AI의 일반적인 사회적, 윤리적 영향에 대해 논의하겠습니다. 의료 분야에서 AI 응용은 효율성을 증가시키고 진단을 개선하는 등 거대한 이점이 있습니다. 그러나 고려해야 할 윤리적 이슈가 있습니다. 첫째로, AI는 대량의 데이터를 필요로 하므로 환자의 개인정보 보호는 중요한 문제입니다. 안전하고 윤리적인 데이터 처리를 보장하는 것이 중요합니다. 둘째로, 훈련 데이터에 다양성이 부족하면 AI 시스템이 편향될 수 있어, 건강 관리 결과에 불평등이 생길 수 있습니다. 마지막으로, AI 사용으로 인해 의료 분야에서의 인간 간 상호작용이 감소할 수 있어, 환자의 경험에 영향을 줄 수 있습니다.

Q2.2: 설명 가능한 AI

사람 전문가들조차 의료 이미지로부터 환자의 인종을 식별할 수 없는데 AI 예측 모델이 그것을 할 수 있다면, 그러한 모델은 의료 분야에서 사용될 수 있을까요? 이에 대한 답은 윤리적 관점에서 볼 때, '아니오' 입니다. 설명 가능성과 이해 가능성은 윤리적 AI 사용의 핵심 원칙입니다. AI가 결정에 이르게 된 과정을 이해하지 못하면, 공정성, 책임성, 또는 오류를 바로잡는 것을 보장할 수 없습니다. '블랙 박스' 모델에 의존하게 되면 잘못된 예측을 내놓을 수 있고, 이는 특히 의료 분야에서는 생명을 위협할 수 있습니다. 이러한 AI 시스템이 설명 가능하고 그들의 결정이 해석 가능할 때까지, 그들의 사용은 의료와 같은 중요한 분야에서 제한되거나 인간의 감독과 결합되어야 합니다.

Q2.3: 의사 결정

의료 분야에서 AI 모델의 결과를 해석할 때 고려해야 할 사항들은 다음과 같습니다: 신뢰성, 모델의 정확성이 다양하고 독립적인 데이터로 검증되었는지를 이해하는 것; 설명 가능성, 모델의 결정이 해석 가능한지; 공정성, 모델이 특정 그룹에 대해 편향되지 않았는지 확인하는 것; 그리고 잘못된 결정의 결과, 특히 생명이 위험에 처할 때입니다. 또한, AI의 결정을 검증하고 환자의 권리가 보호되는지 확인하기 위해 인간의 감독이 있어야 합니다. AI 모델은 인간의 판단을 대체하는 것이 아니라 보완해야 합니다



예상 문제

데이터 과학에서 윤리(Ethics)의 역할에 대해 설명하시오. 특히, 데이터 과학자가 윤리적인 결정을 내리는 데 필요한 요소에 대해 간략히 서술하시오.

답변 예시:
데이터 과학에서 윤리는 중요한 역할을 합니다. 데이터 과학자는 데이터를 수집, 분석, 해석할 때 항상 윤리적인 가이드라인을 따라야 합니다. 이는 개인정보 보호, 공정한 데이터 사용, 편향의 최소화 등을 포함합니다.

Answer example:
Ethics plays a crucial role in data science. Data scientists must adhere to ethical guidelines when collecting, analyzing, and interpreting data. This includes protecting personal information, using data fairly, and minimizing bias.

연구 활동에서의 윤리 준수의 중요성에 대해 설명하시오. 특히, 동의 얻기, 개인정보 보호, 데이터의 기밀성 보장 등에 대해 간략히 서술하시오.

답변 예시:
연구 활동에서 윤리 준수는 필수적입니다. 연구 참여자로부터 동의를 얻는 것, 개인정보를 보호하는 것, 수집된 데이터의 기밀성을 보장하는 것 등이 중요합니다.

Answer example:
Adherence to ethics in research activities is essential. It is important to obtain consent from research participants, protect personal information, and ensure the confidentiality of collected data.

의무론(Deontology)과 목적론(Teleology)의 차이점에 대해 설명하시오. 또한, 이 두 가지 윤리적 접근법이 데이터 과학자의 결정에 어떻게 영향을 미치는지 예를 들어 설명하시오.

답변 예시:
의무론은 행동의 선과 악을 판단하는 규칙이나 규범에 초점을 맞추며, 목적론은 행동의 결과에 초점을 맞춥니다. 예를 들어, 데이터 과학자가 데이터를 사용할 때 의무론적 접근법은 데이터 사용의 규칙을 따르는 것을 중요시하고, 목적론적 접근법은 데이터 사용의 결과를 중요시합니다.

Answer example:
Deontology focuses on rules or norms for judging the goodness or badness of actions, while teleology focuses on the outcomes of actions. For example, when a data scientist uses data, a deontological approach values adherence to rules of data use, while a teleological approach values the outcomes of data use.




